{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<connection object at 0x7f7719634050; dsn: 'dbname=tweets user=patrick', closed: 0>\n",
      "Number of users:  1375\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import datetime\n",
    "import psycopg2 as ppg\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "con = ppg.connect(\"dbname=tweets user=patrick\")\n",
    "print con\n",
    "\n",
    "usa = (-125.6791025,25.4180700649,-66.885417,\n",
    "                           49.3284551525)\n",
    "la = ( -119.578941, 32.799580, -114.130814, 35.809120)\n",
    "    \n",
    "def in_place(pts, box, long_field='tweet_long', lat_field='tweet_lat'):\n",
    "    return pd.Series((pts[long_field] > box[0]) & \n",
    "                     (pts[lat_field] > box[1]) &\n",
    "                     (pts[long_field] < box[2]) &\n",
    "                     (pts[lat_field] < box[3]))\n",
    "\n",
    "with con.cursor() as cur:\n",
    "    cur.execute(\"SELECT tw.tweet_id, tw.user_id, tw.lat as tweet_lat, tw.long as tweet_long, \"\n",
    "                \"tw.created_at, user_locs.followers_count,user_locs.friends_count, \"\n",
    "                \"user_locs.place as user_location, plcs.user_lat, \"\n",
    "                \"plcs.user_long \"\n",
    "                \"FROM tweets as tw, (SELECT user_id, place, friends_count, followers_count \"\n",
    "                \"FROM users) as user_locs, \"\n",
    "                \"(SELECT place, coded_lat as user_lat, coded_long as user_long FROM \"\n",
    "                \"places) as plcs \"\n",
    "                \"WHERE tw.user_id = user_locs.user_id and user_locs.place != 'None' \"\n",
    "                \"and plcs.place = user_locs.place AND plcs.user_lat != -500 AND \"\n",
    "                \"plcs.user_long != 500 AND (user_locs.place ~* '[A-Z\\s]+,\\s*[A-Z]+' OR \"\n",
    "                \"user_locs.place ~* '(New York City|NYC|LA|Los Angeles|Chicago|DC|SF|San Francisco|\"\n",
    "                \"Detroit|Houston|Dallas|Atlanta|Philly|Philadelphia|Phoenix|San Antonio| \"\n",
    "                \"San Jose|Austin|Jacksonville|Indianapolis|Denver)') AND \"\n",
    "                \"tw.text !~* '#insurancejobs|#jobs?|#hiring|#tweetmyjobs';\")\n",
    "    \n",
    "    geotags = pd.DataFrame(cur.fetchall(), \n",
    "                       columns=[c[0] for c in cur.description])\n",
    "    \n",
    "geotags['in_us'] = in_place(geotags[['tweet_long','tweet_lat']], usa)\n",
    "geotags['in_la'] = in_place(geotags[['tweet_long','tweet_lat']], la)\n",
    "\n",
    "geotags= geotags.merge(geotags.groupby('user_id').apply(lambda x: pd.Series(x.shape[0], index=['num_tweets_user'])),\n",
    "                    left_on='user_id', right_index=True, how='left')\n",
    "\n",
    "# drop certain users\n",
    "geotags = geotags[(geotags.followers_count < 2000) & \n",
    "                  (geotags.friends_count < 1800) &\n",
    "                  (geotags.num_tweets_user < 200) &\n",
    "                  (geotags.num_tweets_user >= 3) &\n",
    "                  (geotags.friends_count / geotags.followers_count >= 0.25)]\n",
    "\n",
    "# look at distance between user location and tweet location\n",
    "\n",
    "geotags['tweet_distance'] = np.sqrt((geotags.user_lat - geotags.tweet_lat) ** 2 + \n",
    "                                    (geotags.user_long - geotags.tweet_long) ** 2)\n",
    "geotags['on_road'] = geotags['tweet_distance'] > 0.5\n",
    "geotags['time_of_day'] =  geotags.created_at.map(lambda x: x.hour)\n",
    "\n",
    "# get number of users w/ any on-road tweets, other per-user stats\n",
    "users_on_road=geotags.groupby('user_id').apply(lambda x: pd.Series([x.on_road.any(), x.on_road.sum()],\n",
    "         index=['any_on_road','num_on_road']))\n",
    "geotags = geotags.merge(users_on_road, left_on='user_id', right_index=True)\n",
    "\n",
    "# get locations for tweets in LA\n",
    "import re\n",
    "# get number of distinct users\n",
    "print \"Number of users: \", geotags[geotags.in_la].user_id.drop_duplicates().shape[0]\n",
    "# their locations\n",
    "#print geotags[geotags.in_la][['user_id','user_location']].drop_duplicates().user_location\n",
    "def normalizer(txt):\n",
    "    txt = txt.strip()\n",
    "    txt = txt.lower()\n",
    "    \n",
    "    txt = re.sub(ur\"[,.]\", u\" \", txt,  re.UNICODE)\n",
    "    txt = re.sub(ur\"\\s+\", u\" \", txt, re.UNICODE)\n",
    "    txt = re.sub(ur\"cali[^\\s]+\", u\"ca\", txt, re.UNICODE | re.IGNORECASE)\n",
    "    return txt\n",
    "#print geotags[geotags.in_la][['user_id','user_location']].drop_duplicates().user_location.map(normalizer).value_counts().index.tolist()\n",
    "\n",
    "# get places\n",
    "with con.cursor() as cur:\n",
    "    cur.execute(\"SELECT user_id, place, coded_lat, coded_long FROM users \"\n",
    "                \"JOIN (SELECT place, coded_lat, coded_long FROM places) AS places USING (place)\")\n",
    "    places_df = pd.DataFrame(cur.fetchall(), columns = [c[0] for c in cur.description])\n",
    "places_df['places_norm'] = places_df.place.map(lambda x: x.decode('utf-8')).map(normalizer)\n",
    "places_df = places_df.merge(pd.DataFrame(geotags[geotags.in_la][['user_id','user_location']]. \\\n",
    "                                         drop_duplicates().user_location.map(lambda x: x.decode('utf-8')).\n",
    "                                         map(normalizer)),\n",
    "               left_on='places_norm',right_on='user_location')\n",
    "\n",
    "places_df['in_la'] = places_df['coded_long'].map(lambda x: (x > la[0]) & (x < la[2])) & \\\n",
    "                     places_df['coded_lat'].map(lambda x: (x > la[1]) & (x < la[3])) | \\\n",
    "                    (places_df.places_norm == \"ca\") | (places_df.places_norm == \"la\") | \\\n",
    "                    (places_df.places_norm == 'san diego ca')\n",
    "        \n",
    "# limit to ppl who tweet in LA\n",
    "geotags_la = geotags[geotags.in_la].merge(places_df, on='user_id', suffixes = ('_tweet','_user')).drop_duplicates()\n",
    "\n",
    "with con.cursor() as cur:\n",
    "    cur.execute(\"SELECT tweet_id, text, user_id, tokens FROM tweets\")\n",
    "    tweets_df = pd.DataFrame(cur.fetchall(), columns=[c[0] for c in cur.description])\n",
    "la_tourist_tweets = geotags_la[geotags_la.in_la_user==False].merge(tweets_df, on='tweet_id')\n",
    "la_native_tweets = geotags_la[geotags_la.in_la_user==True].merge(tweets_df, on='tweet_id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# language modeling\n",
    "from nltk.util import ngrams\n",
    "\n",
    "def normalizer(txt):\n",
    "    txt = txt.strip()\n",
    "    txt = txt.lower()\n",
    "    \n",
    "    txt = re.sub(ur\"[,.]\", u\" \", txt,  re.UNICODE)\n",
    "    txt = re.sub(ur\"\\s+\", u\" \", txt, re.UNICODE)\n",
    "    txt = re.sub(ur\"cali[^\\s]+\", u\"ca\", txt, re.UNICODE | re.IGNORECASE)\n",
    "    return txt\n",
    "\n",
    "def add_boundaries(tkns):\n",
    "    return [\"#\"] + tkns + [\"#\"]\n",
    "\n",
    "native_bigrams = ngrams([tkn for tkns in la_native_tweets.tokens.dropna().map(\n",
    "            lambda x: x.decode('utf-8')).map(normalizer). \\\n",
    "                             map(unicode.split).map(add_boundaries) for tkn in tkns], 2)\n",
    "nbg = pd.DataFrame(native_bigrams)\n",
    "nbg['ct'] = 1\n",
    "nbg_df = nbg.groupby([0,1]).agg(['count', lambda x: float(x.count()) / float(nbg.ct.sum())])\n",
    "\n",
    "tourist_bigrams = ngrams([tkn for tkns in la_tourist_tweets.tokens.dropna().map(\n",
    "            lambda x: x.decode('utf-8')).map(normalizer). \\\n",
    "                             map(unicode.split).map(add_boundaries) for tkn in tkns], 2)\n",
    "tbg = pd.DataFrame(tourist_bigrams)\n",
    "tbg['ct'] = 1\n",
    "tbg_df = tbg.groupby([0,1]).agg(['count', lambda x: float(x.count()) / float(tbg.ct.sum())])\n",
    "\n",
    "bigram_models = pd.concat([tbg_df, nbg_df], axis=0, keys=['tourist','not tourist'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">ct</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>&lt;lambda&gt;</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"30\" valign=\"top\">!</th>\n",
       "      <th>#</th>\n",
       "      <th>#</th>\n",
       "      <td> 14</td>\n",
       "      <td> 0.000852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#6thstviaduct</th>\n",
       "      <th>#6thstviaduct</th>\n",
       "      <td>  1</td>\n",
       "      <td> 0.000061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#actress</th>\n",
       "      <th>#actress</th>\n",
       "      <td>  1</td>\n",
       "      <td> 0.000061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#bnsbrewing</th>\n",
       "      <th>#bnsbrewing</th>\n",
       "      <td>  1</td>\n",
       "      <td> 0.000061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#ca</th>\n",
       "      <th>#ca</th>\n",
       "      <td>  1</td>\n",
       "      <td> 0.000061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#chips</th>\n",
       "      <th>#chips</th>\n",
       "      <td>  1</td>\n",
       "      <td> 0.000061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#darpadrc</th>\n",
       "      <th>#darpadrc</th>\n",
       "      <td>  1</td>\n",
       "      <td> 0.000061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#disneyland</th>\n",
       "      <th>#disneyland</th>\n",
       "      <td>  1</td>\n",
       "      <td> 0.000061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#dodgerstadium</th>\n",
       "      <th>#dodgerstadium</th>\n",
       "      <td>  1</td>\n",
       "      <td> 0.000061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#dope</th>\n",
       "      <th>#dope</th>\n",
       "      <td>  1</td>\n",
       "      <td> 0.000061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#e3</th>\n",
       "      <th>#e3</th>\n",
       "      <td>  1</td>\n",
       "      <td> 0.000061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#endeavor</th>\n",
       "      <th>#endeavor</th>\n",
       "      <td>  1</td>\n",
       "      <td> 0.000061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#fantasyfactory</th>\n",
       "      <th>#fantasyfactory</th>\n",
       "      <td>  1</td>\n",
       "      <td> 0.000061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#getsthehose</th>\n",
       "      <th>#getsthehose</th>\n",
       "      <td>  1</td>\n",
       "      <td> 0.000061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#hallelucci</th>\n",
       "      <th>#hallelucci</th>\n",
       "      <td>  1</td>\n",
       "      <td> 0.000061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#haveaseat</th>\n",
       "      <th>#haveaseat</th>\n",
       "      <td>  1</td>\n",
       "      <td> 0.000061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#heedmagazine</th>\n",
       "      <th>#heedmagazine</th>\n",
       "      <td>  1</td>\n",
       "      <td> 0.000061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#insidious3</th>\n",
       "      <th>#insidious3</th>\n",
       "      <td>  1</td>\n",
       "      <td> 0.000061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#lafilmfest</th>\n",
       "      <th>#lafilmfest</th>\n",
       "      <td>  1</td>\n",
       "      <td> 0.000061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#letgola</th>\n",
       "      <th>#letgola</th>\n",
       "      <td>  1</td>\n",
       "      <td> 0.000061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#love</th>\n",
       "      <th>#love</th>\n",
       "      <td>  1</td>\n",
       "      <td> 0.000061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#madebylaurenb</th>\n",
       "      <th>#madebylaurenb</th>\n",
       "      <td>  1</td>\n",
       "      <td> 0.000061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#mangos</th>\n",
       "      <th>#mangos</th>\n",
       "      <td>  1</td>\n",
       "      <td> 0.000061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#mels</th>\n",
       "      <th>#mels</th>\n",
       "      <td>  1</td>\n",
       "      <td> 0.000061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#momsdriving</th>\n",
       "      <th>#momsdriving</th>\n",
       "      <td>  1</td>\n",
       "      <td> 0.000061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#nomnom</th>\n",
       "      <th>#nomnom</th>\n",
       "      <td>  1</td>\n",
       "      <td> 0.000061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#o</th>\n",
       "      <th>#o</th>\n",
       "      <td>  1</td>\n",
       "      <td> 0.000061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#onthemove</th>\n",
       "      <th>#onthemove</th>\n",
       "      <td>  1</td>\n",
       "      <td> 0.000061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#platinumblonde</th>\n",
       "      <th>#platinumblonde</th>\n",
       "      <td>  1</td>\n",
       "      <td> 0.000061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#scenery</th>\n",
       "      <th>#scenery</th>\n",
       "      <td>  1</td>\n",
       "      <td> 0.000061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">🙌🏾</th>\n",
       "      <th>great</th>\n",
       "      <th>great</th>\n",
       "      <td>  1</td>\n",
       "      <td> 0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>💯😭😂</th>\n",
       "      <th>💯😭😂</th>\n",
       "      <td>  1</td>\n",
       "      <td> 0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>🙌🏾😚🙊🙈🙉💋</th>\n",
       "      <th>@bythewayfilm</th>\n",
       "      <th>@bythewayfilm</th>\n",
       "      <td>  1</td>\n",
       "      <td> 0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">🙌🏿</th>\n",
       "      <th>(</th>\n",
       "      <th>(</th>\n",
       "      <td>  1</td>\n",
       "      <td> 0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@</th>\n",
       "      <th>@</th>\n",
       "      <td>  1</td>\n",
       "      <td> 0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>🙌👌✨👏</th>\n",
       "      <th>ive</th>\n",
       "      <th>ive</th>\n",
       "      <td>  1</td>\n",
       "      <td> 0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>🙌🙌👌🙏</th>\n",
       "      <th>#</th>\n",
       "      <th>#</th>\n",
       "      <td>  1</td>\n",
       "      <td> 0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">🙏</th>\n",
       "      <th>#</th>\n",
       "      <th>#</th>\n",
       "      <td>  1</td>\n",
       "      <td> 0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thank</th>\n",
       "      <th>thank</th>\n",
       "      <td>  2</td>\n",
       "      <td> 0.000020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>🙏thank</th>\n",
       "      <th>you</th>\n",
       "      <th>you</th>\n",
       "      <td>  1</td>\n",
       "      <td> 0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>🙏🏻</th>\n",
       "      <th>#practicemakesperfect</th>\n",
       "      <th>#practicemakesperfect</th>\n",
       "      <td>  1</td>\n",
       "      <td> 0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">🙏🏼</th>\n",
       "      <th>#</th>\n",
       "      <th>#</th>\n",
       "      <td>  1</td>\n",
       "      <td> 0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stop</th>\n",
       "      <th>stop</th>\n",
       "      <td>  1</td>\n",
       "      <td> 0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>🙏🏽🎶</th>\n",
       "      <th>@</th>\n",
       "      <th>@</th>\n",
       "      <td>  1</td>\n",
       "      <td> 0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>🙏💕</th>\n",
       "      <th>#forevergrateful</th>\n",
       "      <th>#forevergrateful</th>\n",
       "      <td>  1</td>\n",
       "      <td> 0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>🙏💯</th>\n",
       "      <th>#istayfit</th>\n",
       "      <th>#istayfit</th>\n",
       "      <td>  1</td>\n",
       "      <td> 0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>🚀🌛</th>\n",
       "      <th>@8biteric</th>\n",
       "      <th>@8biteric</th>\n",
       "      <td>  1</td>\n",
       "      <td> 0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>🚎</th>\n",
       "      <th>trailer</th>\n",
       "      <th>trailer</th>\n",
       "      <td>  4</td>\n",
       "      <td> 0.000040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>🚘✨🙌</th>\n",
       "      <th>#</th>\n",
       "      <th>#</th>\n",
       "      <td>  1</td>\n",
       "      <td> 0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>🚚</th>\n",
       "      <th>video</th>\n",
       "      <th>video</th>\n",
       "      <td>  1</td>\n",
       "      <td> 0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>🚢</th>\n",
       "      <th>#</th>\n",
       "      <th>#</th>\n",
       "      <td>  1</td>\n",
       "      <td> 0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>🚦🚘</th>\n",
       "      <th>@</th>\n",
       "      <th>@</th>\n",
       "      <td>  1</td>\n",
       "      <td> 0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>🚧</th>\n",
       "      <th>#fearfactor</th>\n",
       "      <th>#fearfactor</th>\n",
       "      <td>  2</td>\n",
       "      <td> 0.000020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>🚪</th>\n",
       "      <th>is</th>\n",
       "      <th>is</th>\n",
       "      <td>  1</td>\n",
       "      <td> 0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>🚫🍞😷</th>\n",
       "      <th>@</th>\n",
       "      <th>@</th>\n",
       "      <td>  1</td>\n",
       "      <td> 0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>🚬🚬🚬🚬🚬</th>\n",
       "      <th>@la_dollhouse</th>\n",
       "      <th>@la_dollhouse</th>\n",
       "      <td>  1</td>\n",
       "      <td> 0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>🚮🚮🚮🚮🚮🚮</th>\n",
       "      <th>#</th>\n",
       "      <th>#</th>\n",
       "      <td>  1</td>\n",
       "      <td> 0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>🚯</th>\n",
       "      <th>wasting</th>\n",
       "      <th>wasting</th>\n",
       "      <td>  3</td>\n",
       "      <td> 0.000030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>🚴</th>\n",
       "      <th>@</th>\n",
       "      <th>@</th>\n",
       "      <td>  1</td>\n",
       "      <td> 0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>🚽♨️</th>\n",
       "      <th>#</th>\n",
       "      <th>#</th>\n",
       "      <td>  1</td>\n",
       "      <td> 0.000010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72379 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       ct          \n",
       "                                                    count  <lambda>\n",
       "        0                     1                                    \n",
       "!       #                     #                        14  0.000852\n",
       "        #6thstviaduct         #6thstviaduct             1  0.000061\n",
       "        #actress              #actress                  1  0.000061\n",
       "        #bnsbrewing           #bnsbrewing               1  0.000061\n",
       "        #ca                   #ca                       1  0.000061\n",
       "        #chips                #chips                    1  0.000061\n",
       "        #darpadrc             #darpadrc                 1  0.000061\n",
       "        #disneyland           #disneyland               1  0.000061\n",
       "        #dodgerstadium        #dodgerstadium            1  0.000061\n",
       "        #dope                 #dope                     1  0.000061\n",
       "        #e3                   #e3                       1  0.000061\n",
       "        #endeavor             #endeavor                 1  0.000061\n",
       "        #fantasyfactory       #fantasyfactory           1  0.000061\n",
       "        #getsthehose          #getsthehose              1  0.000061\n",
       "        #hallelucci           #hallelucci               1  0.000061\n",
       "        #haveaseat            #haveaseat                1  0.000061\n",
       "        #heedmagazine         #heedmagazine             1  0.000061\n",
       "        #insidious3           #insidious3               1  0.000061\n",
       "        #lafilmfest           #lafilmfest               1  0.000061\n",
       "        #letgola              #letgola                  1  0.000061\n",
       "        #love                 #love                     1  0.000061\n",
       "        #madebylaurenb        #madebylaurenb            1  0.000061\n",
       "        #mangos               #mangos                   1  0.000061\n",
       "        #mels                 #mels                     1  0.000061\n",
       "        #momsdriving          #momsdriving              1  0.000061\n",
       "        #nomnom               #nomnom                   1  0.000061\n",
       "        #o                    #o                        1  0.000061\n",
       "        #onthemove            #onthemove                1  0.000061\n",
       "        #platinumblonde       #platinumblonde           1  0.000061\n",
       "        #scenery              #scenery                  1  0.000061\n",
       "...                                                   ...       ...\n",
       "🙌🏾      great                 great                     1  0.000010\n",
       "        💯😭😂                   💯😭😂                       1  0.000010\n",
       "🙌🏾😚🙊🙈🙉💋 @bythewayfilm         @bythewayfilm             1  0.000010\n",
       "🙌🏿      (                     (                         1  0.000010\n",
       "        @                     @                         1  0.000010\n",
       "🙌👌✨👏    ive                   ive                       1  0.000010\n",
       "🙌🙌👌🙏    #                     #                         1  0.000010\n",
       "🙏       #                     #                         1  0.000010\n",
       "        thank                 thank                     2  0.000020\n",
       "🙏thank  you                   you                       1  0.000010\n",
       "🙏🏻      #practicemakesperfect #practicemakesperfect     1  0.000010\n",
       "🙏🏼      #                     #                         1  0.000010\n",
       "        stop                  stop                      1  0.000010\n",
       "🙏🏽🎶     @                     @                         1  0.000010\n",
       "🙏💕      #forevergrateful      #forevergrateful          1  0.000010\n",
       "🙏💯      #istayfit             #istayfit                 1  0.000010\n",
       "🚀🌛      @8biteric             @8biteric                 1  0.000010\n",
       "🚎       trailer               trailer                   4  0.000040\n",
       "🚘✨🙌     #                     #                         1  0.000010\n",
       "🚚       video                 video                     1  0.000010\n",
       "🚢       #                     #                         1  0.000010\n",
       "🚦🚘      @                     @                         1  0.000010\n",
       "🚧       #fearfactor           #fearfactor               2  0.000020\n",
       "🚪       is                    is                        1  0.000010\n",
       "🚫🍞😷     @                     @                         1  0.000010\n",
       "🚬🚬🚬🚬🚬   @la_dollhouse         @la_dollhouse             1  0.000010\n",
       "🚮🚮🚮🚮🚮🚮  #                     #                         1  0.000010\n",
       "🚯       wasting               wasting                   3  0.000030\n",
       "🚴       @                     @                         1  0.000010\n",
       "🚽♨️     #                     #                         1  0.000010\n",
       "\n",
       "[72379 rows x 2 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
